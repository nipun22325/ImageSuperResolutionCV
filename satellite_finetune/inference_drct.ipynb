{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 0: img_19\n",
      "Saved: results/DRCT-L_X4/img_19_DRCT-L_X4.png\n",
      "Processing 1: img_23\n",
      "Saved: results/DRCT-L_X4/img_23_DRCT-L_X4.png\n",
      "Processing 2: img_27\n",
      "Saved: results/DRCT-L_X4/img_27_DRCT-L_X4.png\n",
      "Processing 3: img_9\n",
      "Saved: results/DRCT-L_X4/img_9_DRCT-L_X4.png\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from drct.archs.DRCT_arch import DRCT  # Make sure the path to DRCT_arch is correct\n",
    "\n",
    "# Define arguments manually\n",
    "class Args:\n",
    "    model_path = \"/home/rahul_b/Run1/DRCT/experiments/train_DRCT-L_SRx4_finetune_from_ImageNet_pretrain_archived_20250419_230123/models/net_g_latest.pth\"\n",
    "    input = \"/home/rahul_b/Run1/data/val/LR\"\n",
    "    output = \"results/DRCT-L_X4\"\n",
    "    scale = 4\n",
    "    tile = None\n",
    "    tile_overlap = 32\n",
    "\n",
    "args = Args()\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = DRCT(\n",
    "    upscale=4, in_chans=3, img_size=64, window_size=16, compress_ratio=3,\n",
    "    squeeze_factor=30, conv_scale=0.01, overlap_ratio=0.5, img_range=1.,\n",
    "    depths=[6]*12, embed_dim=180, num_heads=[6]*12, gc=32, mlp_ratio=2,\n",
    "    upsampler='pixelshuffle', resi_connection='1conv'\n",
    ")\n",
    "model.load_state_dict(torch.load(args.model_path)['params'], strict=True)\n",
    "model.eval()\n",
    "model = model.to(device)\n",
    "\n",
    "window_size = 16\n",
    "os.makedirs(args.output, exist_ok=True)\n",
    "\n",
    "def test(img_lq, model, args, window_size):\n",
    "    if args.tile is None:\n",
    "        output = model(img_lq)\n",
    "    else:\n",
    "        b, c, h, w = img_lq.size()\n",
    "        tile = min(args.tile, h, w)\n",
    "        assert tile % window_size == 0\n",
    "        stride = tile - args.tile_overlap\n",
    "        sf = args.scale\n",
    "\n",
    "        h_idx_list = list(range(0, h-tile, stride)) + [h-tile]\n",
    "        w_idx_list = list(range(0, w-tile, stride)) + [w-tile]\n",
    "\n",
    "        E = torch.zeros(b, c, h*sf, w*sf).type_as(img_lq)\n",
    "        W = torch.zeros_like(E)\n",
    "\n",
    "        for h_idx in h_idx_list:\n",
    "            for w_idx in w_idx_list:\n",
    "                in_patch = img_lq[..., h_idx:h_idx+tile, w_idx:w_idx+tile]\n",
    "                out_patch = model(in_patch)\n",
    "                out_patch_mask = torch.ones_like(out_patch)\n",
    "\n",
    "                E[..., h_idx*sf:(h_idx+tile)*sf, w_idx*sf:(w_idx+tile)*sf].add_(out_patch)\n",
    "                W[..., h_idx*sf:(h_idx+tile)*sf, w_idx*sf:(w_idx+tile)*sf].add_(out_patch_mask)\n",
    "        output = E.div_(W)\n",
    "\n",
    "    return output\n",
    "\n",
    "\n",
    "for idx, path in enumerate(sorted(glob.glob(os.path.join(args.input, '*')))):\n",
    "    imgname = os.path.splitext(os.path.basename(path))[0]\n",
    "    print(f\"Processing {idx}: {imgname}\")\n",
    "\n",
    "    img = cv2.imread(path, cv2.IMREAD_COLOR).astype(np.float32) / 255.\n",
    "    img = torch.from_numpy(np.transpose(img[:, :, [2, 1, 0]], (2, 0, 1))).float()\n",
    "    img = img.unsqueeze(0).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        _, _, h_old, w_old = img.size()\n",
    "        h_pad = (h_old // window_size + 1) * window_size - h_old\n",
    "        w_pad = (w_old // window_size + 1) * window_size - w_old\n",
    "\n",
    "        img = torch.cat([img, torch.flip(img, [2])], 2)[:, :, :h_old + h_pad, :]\n",
    "        img = torch.cat([img, torch.flip(img, [3])], 3)[:, :, :, :w_old + w_pad]\n",
    "\n",
    "        output = test(img, model, args, window_size)\n",
    "        output = output[..., :h_old * args.scale, :w_old * args.scale]\n",
    "\n",
    "        output = output.data.squeeze().float().cpu().clamp_(0, 1).numpy()\n",
    "        output = np.transpose(output[[2, 1, 0], :, :], (1, 2, 0))\n",
    "        output = (output * 255.0).round().astype(np.uint8)\n",
    "\n",
    "        out_path = os.path.join(args.output, f'{imgname}_DRCT-L_X4.png')\n",
    "        cv2.imwrite(out_path, output)\n",
    "        print(f\"Saved: {out_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.20 ('drct': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "29acdee78c3758710bd18bfd9eb43b50d08ce415683eda65f75d82822f94488d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
